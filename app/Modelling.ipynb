{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24c05e5",
   "metadata": {},
   "source": [
    "# Special kursus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc4f722",
   "metadata": {},
   "source": [
    "## Import of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d95178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=f'{0}'\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch\n",
    "\n",
    "from modules import dataHandler, dataprocessing, models\n",
    "from modules import scalers as scaling\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5fa942",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"cuda {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"cpu\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a288a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87600474",
   "metadata": {},
   "source": [
    "Loads all the different datasets: Regions, TS profiles, Bathymetri, GHRSST and SMOS.\\\n",
    "The TS profiles also gets cleaned and split into different regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1ed4fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bathymetri [2/4]          \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehkj/Developer/NEURAL-NETWORK-FOR-ARCTIC-CLIMATE-DATA/modules/dataHandler.py:335: UserWarning: WARNING: valid_min not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  bathymetri_topography: np.ndarray = bathymetri['bedrock_topography'][:].data[bathymetri_lat > 60, :]\n",
      "/Users/mehkj/Developer/NEURAL-NETWORK-FOR-ARCTIC-CLIMATE-DATA/modules/dataHandler.py:335: UserWarning: WARNING: valid_max not used since it\n",
      "cannot be safely cast to variable data type\n",
      "  bathymetri_topography: np.ndarray = bathymetri['bedrock_topography'][:].data[bathymetri_lat > 60, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOS [4/4]            \r"
     ]
    }
   ],
   "source": [
    "(\n",
    "    regions,\n",
    "    ts_profiles,\n",
    "    bathymetri_lat, bathymetri_lon, bathymetri_topography,\n",
    "    ghrsst_lat, ghrsst_lon, ghrsst_sst, ghrsst_times, ghrsst_fraction_time, ghrsst_time_bnds,\n",
    "    smos_sss, smos_time, smos_lat, smos_lon\n",
    ") = dataHandler.load_all(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59e22986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mehkj/Developer/NEURAL-NETWORK-FOR-ARCTIC-CLIMATE-DATA/modules/dataprocessing.py:24: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  points = gp.GeoDataFrame(ts_profiles.point, columns=['geometry']).set_crs(4326)\n",
      "/Users/mehkj/Developer/NEURAL-NETWORK-FOR-ARCTIC-CLIMATE-DATA/modules/dataHandler.py:226: FutureWarning: The input object of type 'Point' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Point', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array([getattr(profile, __name) for profile in self.profiles], dtype=self.__get_type(out))\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/NNACD/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3251: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "ts_areas = dataprocessing.split_regions(ts_profiles, regions.set_crs(4326))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2a273",
   "metadata": {},
   "source": [
    "## Creation of training, validation and testing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd82ec",
   "metadata": {},
   "source": [
    "The following code splits the dataset into 3 datasets (training, valdiation and testing).\\\n",
    "The data outside the ghrsst time is cut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e09ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_time, max_time = min(ghrsst_fraction_time), max(ghrsst_fraction_time)\n",
    "training_end = 2012\n",
    "validation_end = 2015\n",
    "train, val, test, areas = dataprocessing.split_data_set(ts_areas, training_end, validation_end, min_time, max_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b962cb6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521af855",
   "metadata": {},
   "source": [
    "Converts the dict objects into dataloaders containing torch tensors and scales each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09fcd5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = [\n",
    "    scaling.MeanScaling, # lat\n",
    "    scaling.MeanScaling, # lon\n",
    "    scaling.MeanScaling, # year\n",
    "    scaling.MeanScaling, # decimal year\n",
    "    scaling.MeanScaling, # sss\n",
    "    scaling.MeanScaling, # sst\n",
    "    scaling.MeanScaling, # surface depth\n",
    "    scaling.MinMaxScaling, # bathymetri\n",
    "    scaling.MeanScaling, # salinity profile\n",
    "    scaling.MeanScaling, # temperature profile\n",
    "]\n",
    "\n",
    "scalers, train_loader, val_loader, test_loader = dataprocessing.process_data(\n",
    "    train=train,\n",
    "    val=val,\n",
    "    test=test,\n",
    "    bathymetri_lat=bathymetri_lat,\n",
    "    bathymetri_lon=bathymetri_lon,\n",
    "    bathymetri_topography=bathymetri_topography,\n",
    "    scalers= scalers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c471ae",
   "metadata": {},
   "source": [
    "Trains the model and saves it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32944897",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\n",
      "\tRNN:\n",
      "\t\tInput 8, Output 21, Layers 2\n",
      "\tLinear:\n",
      "\t\tInput 21, Output 21, Layers 1\n",
      "Optimizer:\n",
      "\tlr 0.5, momentum 0.8 weight decay 0.0001\n",
      "\n",
      "[  1/100] Salinity Training Loss 1.49739, lr 0.500 | Validation Loss 1.21736, MedAE 0.865\n",
      "[ 10/100] Salinity Training Loss 0.75499, lr 0.490 | Validation Loss 0.48421, MedAE 0.312\n",
      "[ 20/100] Salinity Training Loss 0.60842, lr 0.457 | Validation Loss 0.46368, MedAE 0.301\n",
      "[ 30/100] Salinity Training Loss 0.56430, lr 0.403 | Validation Loss 0.46259, MedAE 0.309\n",
      "[ 40/100] Salinity Training Loss 0.58190, lr 0.335 | Validation Loss 0.48199, MedAE 0.329\n",
      "[ 50/100] Salinity Training Loss 0.54648, lr 0.258 | Validation Loss 0.45904, MedAE 0.312\n",
      "[ 60/100] Salinity Training Loss 0.54855, lr 0.181 | Validation Loss 0.44789, MedAE 0.299\n",
      "[ 70/100] Salinity Training Loss 0.51197, lr 0.110 | Validation Loss 0.44737, MedAE 0.298\n",
      "[ 80/100] Salinity Training Loss 0.49636, lr 0.053 | Validation Loss 0.44973, MedAE 0.300\n",
      "[ 90/100] Salinity Training Loss 0.49082, lr 0.016 | Validation Loss 0.44906, MedAE 0.299\n",
      "[100/100] Salinity Training Loss 0.48937, lr 0.001 | Validation Loss 0.44752, MedAE 0.298\n"
     ]
    }
   ],
   "source": [
    "training_loss, validation_loss = models.train_model(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e9fb0c-3ffe-4743-9052-d495124354ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
